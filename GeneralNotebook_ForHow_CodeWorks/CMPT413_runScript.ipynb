{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for informational purposes and wont be able to run, as that requires the data to be sent as well\n",
    "\n",
    "However it is a general script that shows how general our code is as we raelly just need ot change the model and datalaoder to be able to run a different model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"/home/prsood/projects/def-whkchun/prsood/multi-modal-emotion/\") \n",
    "__package__ = \"GeneralNotebook_ForHow_CodeWorks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SingleModels.train_model.text_training import train_text_network, evaluate_text\n",
    "from SingleModels.models.text import BertClassifier\n",
    "import wandb\n",
    "\n",
    "from utils.data_loaders import BertDataset\n",
    "from utils.global_functions import arg_parse \n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.global_functions import arg_parse , hidden_layer_count , Metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(df , batch_size, pin_memory=True, num_workers=4):\n",
    "    \"\"\"\n",
    "    we load in our dataset, and we just make a random distributed sampler to evenly partition our \n",
    "    dataset on each GPU\n",
    "    say we have 32 data points, if batch size = 8 then it will make 4 dataloaders of size 8 each \n",
    "    \"\"\"\n",
    "    max_len = 70 # just max number of tokens from LSTM    keep this line in here somewhere\n",
    "\n",
    "    dataset = BertDataset(df , max_len)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, pin_memory=pin_memory, \n",
    "            num_workers=num_workers, drop_last=False, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set our hyperparameters, and add in our metrics and criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 70 # just max number of tokens from LSTM    keep this line in here somewhere\n",
    "epoch = param_dict['epoch']\n",
    "lr = param_dict['lr']\n",
    "patience = param_dict['patience']\n",
    "clip = param_dict['clip']\n",
    "T_max = param_dict['T_max']\n",
    "batch_size = param_dict['batch_size']\n",
    "weight_decay = param_dict['weight_decay']\n",
    "weights = param_dict['weights']\n",
    "label2id = param_dict['label2id']\n",
    "id2label = param_dict['id2label']\n",
    "\n",
    "num_labels = model_param['output_dim']\n",
    "input_dim = model_param['input_dim']\n",
    "lstm_layers = model_param['lstm_layers']\n",
    "hidden_layers = model_param['hidden_layers']\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(rank)\n",
    "Metric = Metrics(num_classes = num_labels, id2label = id2label , rank = rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to convert the dataframe to the dataloader and intialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = prepare_dataloader(df_train, batch_size = batch_size )\n",
    "df_val = prepare_dataloader(df_val, batch_size = batch_size )\n",
    "df_test = prepare_dataloader(df_test , batch_size = batch_size)\n",
    "\n",
    "model = BertClassifier(model_param).to(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train our model on the train and val dataloaders, along with our hyperparameters from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_text_network(model, df_train, df_val, criterion , lr, epoch ,  weight_decay,T_max, Metric , patience , clip )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training loop is quite simple, all it does it just take in the batched inputs, run it through the model, then backpropogate, take a step with our optimizer and zero all the gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we take in whatever our input and labels are and just run them through our model and get back our output\n",
    "\n",
    "If we are in train or val we have the loss function work, else we dont use it\n",
    "\n",
    "Then we get our predicts and labels and update them to our metrics so we can calculate F1, multi F1 Confusion matrices and many more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(input,label,model,criterion,total_loss, Metric):\n",
    "    batch_loss = None\n",
    "    label = label.to(f\"cuda\")\n",
    "\n",
    "    if model.__class__.__name__ == \"BertClassifier\":\n",
    "        mask = input['attention_mask'].to(f\"cuda\")\n",
    "        input_id = input['input_ids'].squeeze(1).to(f\"cuda\")\n",
    "        # print(f\"input_id = {input_id}\")\n",
    "        output = model(input_id, mask)\n",
    "    else:\n",
    "        # pdb.set_trace()\n",
    "        output = model(input) # shape was 16,128,2 , now its 16,2\n",
    "    \n",
    "    if criterion is not None:\n",
    "        batch_loss = criterion(output, label.long())\n",
    "        total_loss += batch_loss.item()\n",
    "        \n",
    "    # print(\"before update metrics\" , flush = True)\n",
    "    # print(f\"output of BERT is {output} \\n shape of output is {output.shape}\\n\")\n",
    "    Metric.update_metrics(torch.argmax(output , dim = 1) , label.long())\n",
    "    return batch_loss , total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one epoch is where we actually do our training. so we just get our statistics from above and just run our three functions\n",
    "\n",
    "model.zero_grad()\n",
    "\n",
    "train_batch_loss.backward()  # Back propagate\n",
    "\n",
    "optimizer.step()\n",
    "\n",
    "to learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_epoch(train_dataloader , model , criterion , optimizer, clip , Metric):\n",
    "    total_loss_train = 0\n",
    "\n",
    "    for train_input, train_label in tqdm(train_dataloader , desc=\"training\"):\n",
    "        # print(\"before getting Stats\" , flush = True)\n",
    "        train_batch_loss , total_loss_train  = get_statistics(train_input , train_label , model , criterion , total_loss_train , Metric)\n",
    "        if clip is not None: # so gradients can beccome super big and super small, this clip is like a little flag that says we are too big or too small, \n",
    "            # lets cut it off here eg. clip is 50, if our gradients are 200 itll jsut make it 50 \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        train_batch_loss.backward()  # Back propagate\n",
    "        optimizer.step()  # Run optimization step\n",
    "    \n",
    "    return  model , optimizer , train_batch_loss,total_loss_train/len(train_dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just have our validation method to run both the validate and testing code as they are quite similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate(val_dataloader , model , criterion, Metric , name = \"val\" , location = \"val\"):\n",
    "    total_loss_val = 0\n",
    "    with torch.no_grad():\n",
    "        for val_input, val_label in tqdm(val_dataloader, desc = \"validate\" if name == \"val\" else \"testing\" ):\n",
    "            val_batch_loss , total_loss_val = get_statistics(val_input , val_label , model , criterion , total_loss_val  , Metric , name , location)\n",
    "\n",
    "    return  val_batch_loss,total_loss_val/len(val_dataloader.dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the general main frame to train and validate our code\n",
    "\n",
    "We just go through each epoch and call the functions above\n",
    "\n",
    "then from there we send our results to WANDB so we can look at them further for Hyper Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_text_network(model, train_dataloader, val_dataloader, criterion , learning_rate, epochs , weight_decay,T_max, Metric , patience = None, clip = None  ) :  # TODO Fill in the information necessary as variables here.\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr = learning_rate , weight_decay=weight_decay)\n",
    "    earlystop = EarlyStopping(\"\",model,patience , model_name=model.__class__.__name__)\n",
    "    scheduler = CosineAnnealingLR(optimizer , T_max=T_max)\n",
    "\n",
    "    for epoch_num in tqdm(range(epochs), desc=\"epochs\"):\n",
    "        # model.train() # we want the model flag for training to be set true, this way the model knows its about to change\n",
    "        optimizer.zero_grad()  # Zero out gradients before each epoch.\n",
    "        \n",
    "        # this is where we start to train our model\n",
    "        model , optimizer , train_batch_loss,train_loss = one_epoch(train_dataloader ,  model , criterion , optimizer , clip , Metric ) \n",
    "        multiAcc , multiF1, multiRec, multiPrec , Acc, F1, Rec, Prec , _ = Metric.compute_scores(\"train\")\n",
    "        d1 = {\n",
    "                \"epoch\": epoch_num,\n",
    "                \"train/batch_loss\": train_batch_loss,\n",
    "                \"train/train_loss\": train_loss,\n",
    "                \"train/acc\": Acc,\n",
    "                \"train/precision\": Prec,\n",
    "                \"train/recall\" : Rec,\n",
    "                \"train/f1-score\": F1,\n",
    "            }\n",
    "        print(f\"\\n in train \\n Confusion Matrix = {_} \\n\")\n",
    "        wandb.log({**d1 , **multiF1, **multiRec, **multiPrec, **multiAcc}) \n",
    "        Metric.reset_metrics()\n",
    "        scheduler.step() \n",
    "\n",
    "        val_batch_loss,val_loss = validate(val_dataloader  , model , criterion , Metric)\n",
    "\n",
    "        multiAcc , multiF1, multiRec, multiPrec , Acc, F1, Rec, Prec , _ = Metric.compute_scores(\"val\")\n",
    "\n",
    "        d1 = {\n",
    "                \"val/batch_loss\": val_batch_loss,\n",
    "                \"val/total_loss_val\": val_loss,\n",
    "                \"val/total_acc_val\": Acc,\n",
    "                \"val/precision\": Prec,\n",
    "                \"val/recall\": Rec,\n",
    "                \"val/f1-score\": F1,\n",
    "                }\n",
    "        print(f\"\\n in val \\n Confusion Matrix = {_} \\n\")\n",
    "        wandb.log({**d1 , **multiF1, **multiRec, **multiPrec, **multiAcc})\n",
    "        Metric.reset_metrics()\n",
    "\n",
    "        if patience is not None: # this is to make sure that gradietn descent isnt stuck in a local minima \n",
    "            if earlystop(model, val_loss):\n",
    "                model = earlystop.best_state\n",
    "                \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we evaluate our test set, which is quite similar to what we did for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_text(model, df_test, Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_text(model, test_dataloader , Metric , location = \"/home/prsood/projects/def-whkchun/prsood/multi-modal-emotion/Inference/bertTest.txt\"):\n",
    "    # model.eval() # this is where we put the flag for evaluating on so we dont change anything by accident\n",
    "    name = \"test\"\n",
    "    validate(test_dataloader  , model , None , Metric , name , location)\n",
    "    multiAcc , multiF1, multiRec, multiPrec , Acc, F1, Rec, Prec , ConfusionMatrix = Metric.compute_scores(\"test\")\n",
    "    d1 = {\n",
    "            \"test/total_acc_test\": Acc,\n",
    "            \"test/precision\": Prec,\n",
    "            \"test/recall\": Rec,\n",
    "            \"test/f1-score\": F1,\n",
    "            \"test/ConfusionMatrix\": ConfusionMatrix,\n",
    "            }\n",
    "    wandb.log({**d1 , **multiF1, **multiRec, **multiPrec, **multiAcc})    \n",
    "    print(f\"\\n in TEST \\n Confusion Matrix = {ConfusionMatrix} \\n\")    \n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('sarcasm_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "682255e32c8b7c7832e1c984c03ff3b577376f85199a15f316109068883e84f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
